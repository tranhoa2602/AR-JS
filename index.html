<!DOCTYPE html>
<html lang="vi">
  <head>
    <meta charset="UTF-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, viewport-fit=cover"
    />
    <title>AR Camera Fixed Model</title>
    <script
      type="module"
      src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"
    ></script>
    <style>
      html,
      body {
        margin: 0;
        height: 100%;
        background: #0b0c10;
        color: #fff;
        font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial,
          sans-serif;
        overflow: hidden;
      }
      model-viewer {
        width: 100%;
        height: 100%;
        --ar-button-display: none;
        background: #0b0c10;
      }

      .button-group {
        position: absolute;
        bottom: 30px;
        left: 50%;
        transform: translateX(-50%);
        display: flex;
        gap: 16px;
        z-index: 10;
      }

      .button-group button {
        flex: 1;
        width: 160px;
        padding: 14px 20px;
        border: none;
        border-radius: 16px;
        font-weight: 600;
        font-size: 15px;
        cursor: pointer;
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 10px;
        box-shadow: 0 8px 24px rgba(0, 0, 0, 0.4);
        transition: transform 0.2s ease, filter 0.25s ease, box-shadow 0.2s ease;
        will-change: transform, filter, box-shadow;
        backdrop-filter: blur(12px);
      }

      .button-group button:hover {
        transform: translateY(-2px);
        filter: brightness(1.1);
        box-shadow: 0 12px 28px rgba(0, 0, 0, 0.5);
      }

      .button-group button:active {
        transform: scale(0.95);
      }

      .ar-btn {
        background: linear-gradient(135deg, #ffd700, #ff8c00);
        color: #1a1a1a;
      }

      .link-btn {
        background: linear-gradient(135deg, #ff3b3b, #d81b60);
        color: #fff;
      }

      .btn-icon {
        font-size: 20px;
        transform: translateY(1px);
      }
    </style>
  </head>
  <body>
    <model-viewer
      id="mv"
      src="module/source/chibialice.glb"
      ios-src="https://raw.githubusercontent.com/tranhoa2602/AR-JS/main/ChibiAlice.usdz"
      ar
      autoplay
      camera-controls
      ar-modes="scene-viewer webxr quick-look"
      ar-scale="Fixed"
      ar-placement="floor"
      alt="Chibi Alice"
    >
    </model-viewer>

    <div class="button-group">
      <button class="ar-btn" id="customAR">
        <span class="btn-icon">üï∂Ô∏è</span> Xem AR
      </button>
      <button
        class="link-btn"
        onclick="window.open('https://www.youtube.com/watch?v=31NuzJ_aTUk', '_blank')"
      >
        <span class="btn-icon">‚ñ∂Ô∏è</span> Gh√© ThƒÉm
      </button>
    </div>

    <audio
      id="Sound"
      src="https://raw.githubusercontent.com/tranhoa2602/AR-JS/main/timo-timo.mp3"
      preload="auto"
      loop
    ></audio>

    <script>
      const mv = document.getElementById("mv");
      const Sound = document.getElementById("Sound");
      const customAR = document.getElementById("customAR");

      // Kh·ªüi t·∫°o Web Audio Context cho iOS
      let audioContext = null;
      let audioSource = null; // L∆∞u tr·ªØ source ƒë·ªÉ d·ª´ng √¢m thanh

      // H√†m ph√°t audio b·∫±ng Web Audio API v·ªõi ƒë·ªô tr·ªÖ 5 gi√¢y
      async function playAudioInAR() {
        if (!audioContext) {
          audioContext = new (window.AudioContext ||
            window.webkitAudioContext)();
        }
        try {
          // ƒê·∫£m b·∫£o AudioContext ƒë∆∞·ª£c resumed
          if (audioContext.state === "suspended") {
            await audioContext.resume();
          }
          // Fetch v√† ph√°t audio sau 5 gi√¢y
          setTimeout(async () => {
            try {
              const response = await fetch(
                "https://raw.githubusercontent.com/tranhoa2602/AR-JS/main/timo-timo.mp3"
              );
              const arrayBuffer = await response.arrayBuffer();
              const audioBuffer = await audioContext.decodeAudioData(
                arrayBuffer
              );
              const source = audioContext.createBufferSource();
              source.buffer = audioBuffer;
              source.loop = true; // ƒê·∫£m b·∫£o l·∫∑p √¢m thanh
              source.connect(audioContext.destination);
              source.start();
              audioSource = source; // L∆∞u source ƒë·ªÉ d·ª´ng sau n√†y
              console.log("Audio b·∫Øt ƒë·∫ßu ph√°t trong AR sau 5 gi√¢y");
            } catch (e) {
              console.log("Web Audio API l·ªói:", e);
            }
          }, 5000); // ƒê·ªô tr·ªÖ 5 gi√¢y
        } catch (e) {
          console.log("L·ªói kh·ªüi t·∫°o AudioContext:", e);
        }
      }

      // Unlock audio khi click n√∫t AR
      customAR.addEventListener("click", async (event) => {
        event.preventDefault(); // NgƒÉn h√†nh vi m·∫∑c ƒë·ªãnh

        // Kh·ªüi t·∫°o AudioContext n·∫øu ch∆∞a c√≥
        if (!audioContext) {
          audioContext = new (window.AudioContext ||
            window.webkitAudioContext)();
        }

        try {
          // Unlock audio b·∫±ng c√°ch play/pause ng·∫Øn v·ªõi <audio>
          Sound.currentTime = 0;
          const playPromise = Sound.play();
          if (playPromise !== undefined) {
            await playPromise;
            Sound.pause(); // Pause ngay ƒë·ªÉ ch·ªù AR
          }
        } catch (e) {
          console.log("Unlock audio th·∫•t b·∫°i:", e);
          alert(
            "Vui l√≤ng cho ph√©p √¢m thanh trong c√†i ƒë·∫∑t Safari ƒë·ªÉ nghe trong AR!"
          );
        }

        // K√≠ch ho·∫°t AR
        try {
          await mv.activateAR();
        } catch (arErr) {
          console.log("K√≠ch ho·∫°t AR th·∫•t b·∫°i:", arErr);
        }
      });
      mv.addEventListener("ar-status", async (e) => {
        const status = e.detail.status;
        console.log("AR status:", status); // Debug log

        if (status === "session-started") {
          try {
            await playAudioInAR();
            setTimeout(async () => {
              try {
                Sound.currentTime = 0;
                Sound.volume = 0.7; // Gi·∫£m volume ƒë·ªÉ tr√°nh ch√≥i tai
                const playPromise = Sound.play();
                if (playPromise !== undefined) {
                  await playPromise;
                  console.log("Audio ƒëang ph√°t trong AR (HTML audio)");
                }
              } catch (err) {
                console.log("L·ªói ph√°t audio <audio> trong AR:", err);
              }
            }, 50000);
          } catch (err) {
            console.log("L·ªói ph√°t audio trong AR:", err);
            setTimeout(async () => {
              try {
                await Sound.play();
              } catch (retryErr) {
                console.log("Retry audio th·∫•t b·∫°i:", retryErr);
              }
            }, 5100);
          }
        } else if (status === "not-presenting") {
          Sound.pause();
          Sound.currentTime = 0;
          if (audioSource) {
            audioSource.stop(); // D·ª´ng Web Audio API
            audioSource = null;
          }
          if (audioContext) {
            audioContext.suspend(); // Ti·∫øt ki·ªám t√†i nguy√™n
          }
          console.log("Audio d·ª´ng khi tho√°t AR");
        }
      });

      // X·ª≠ l√Ω visibility change (khi app background ho·∫∑c tho√°t AR)
      document.addEventListener("visibilitychange", async () => {
        if (document.hidden) {
          Sound.pause();
          Sound.currentTime = 0;
          if (audioSource) {
            audioSource.stop();
            audioSource = null;
          }
          if (audioContext) {
            audioContext.suspend();
          }
        } else if (
          mv.getStatus &&
          mv.getStatus().status === "session-started"
        ) {
          // Resume audio n·∫øu ƒëang trong AR
          try {
            if (audioContext && audioContext.state === "suspended") {
              await audioContext.resume();
            }
            await playAudioInAR(); // Resume Web Audio API v·ªõi delay
            await Sound.play(); // Resume HTML audio
          } catch (e) {
            console.log("Resume audio th·∫•t b·∫°i:", e);
          }
        }
      });

      // Th√™m touchstart ƒë·ªÉ unlock AudioContext s·ªõm tr√™n iOS
      document.addEventListener(
        "touchstart",
        async () => {
          if (!audioContext) {
            audioContext = new (window.AudioContext ||
              window.webkitAudioContext)();
            await audioContext.resume();
          }
          if (Sound.paused && !Sound.ended) {
            Sound.play()
              .then(() => {
                Sound.pause(); // Unlock nh∆∞ng kh√¥ng ph√°t ngay
              })
              .catch((e) => console.log("Touch unlock th·∫•t b·∫°i:", e));
          }
        },
        { once: true }
      ); // Ch·ªâ ch·∫°y m·ªôt l·∫ßn
    </script>
  </body>
</html>
